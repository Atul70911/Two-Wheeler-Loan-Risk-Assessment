{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n"
      ],
      "metadata": {
        "id": "aEGVzHhTTQa9"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "train_data = pd.read_csv('Assignment_Train.csv')\n",
        "test_data = pd.read_csv('Assignment_Test.csv')"
      ],
      "metadata": {
        "id": "mpVZkpqxsDyi"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess data\n",
        "def preprocess_data(data, is_train=True):\n",
        "    # Convert 'APPLICATION LOGIN DATE' to datetime and extract year and month\n",
        "    data['APPLICATION LOGIN DATE'] = pd.to_datetime(data['APPLICATION LOGIN DATE'], format='%m/%d/%y', errors='coerce')\n",
        "    data['LOGIN_YEAR'] = data['APPLICATION LOGIN DATE'].dt.year\n",
        "    data['LOGIN_MONTH'] = data['APPLICATION LOGIN DATE'].dt.month\n",
        "\n",
        "    # Drop the 'APPLICATION LOGIN DATE' column as it can't be used directly by the model\n",
        "    data = data.drop('APPLICATION LOGIN DATE', axis=1)\n",
        "\n",
        "    # Convert Cibil Score to float, dealing with non-numeric values\n",
        "    data['Cibil Score'] = pd.to_numeric(data['Cibil Score'], errors='coerce')\n",
        "\n",
        "    # Drop columns with too many missing values or irrelevant columns\n",
        "    columns_to_drop = [\n",
        "        'FIRST NAME', 'MIDDLE NAME', 'LAST NAME', 'mobile', 'Personal Email Address',\n",
        "        'Pan Name', 'name', 'vpa', 'upi_name',\n",
        "        'Phone Social Premium.a23games', 'Phone Social Premium.my11',\n",
        "        'Phone Social Premium.rummycircle', 'Phone Social Premium.yatra'\n",
        "    ]\n",
        "\n",
        "    # Drop columns that exist in the DataFrame\n",
        "    data = data.drop(columns=[col for col in columns_to_drop if col in data.columns])\n",
        "\n",
        "    return data\n"
      ],
      "metadata": {
        "id": "SIUKzcC78pY1"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess train and test data\n",
        "train_data = preprocess_data(train_data)\n",
        "test_data = preprocess_data(test_data, is_train=False)"
      ],
      "metadata": {
        "id": "9DJgor0N8s1y"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify numeric and categorical columns\n",
        "numeric_columns = train_data.select_dtypes(include=[np.number]).columns\n",
        "categorical_columns = train_data.select_dtypes(exclude=[np.number]).columns.drop('Application Status')"
      ],
      "metadata": {
        "id": "Z2Vu0kv48w9h"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create preprocessing steps\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median'))\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_columns),\n",
        "        ('cat', categorical_transformer, categorical_columns)\n",
        "    ])"
      ],
      "metadata": {
        "id": "fB6BFCES8z0b"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pipeline with preprocessor and random forest\n",
        "rf_pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
        "])"
      ],
      "metadata": {
        "id": "Z6cUY1wK827B"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the data\n",
        "X = train_data.drop('Application Status', axis=1)\n",
        "y = train_data['Application Status']"
      ],
      "metadata": {
        "id": "0wX3ziD1844K"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "xnYzZHXk88P8"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the pipeline\n",
        "rf_pipeline.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = rf_pipeline.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Make predictions on test data\n",
        "test_predictions = rf_pipeline.predict(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_FGXcCR8-cX",
        "outputId": "4f710f88-d933-4da9-a4a7-a7139cd83281"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.862\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "    APPROVED       0.94      0.85      0.89      1995\n",
            "    DECLINED       0.75      0.89      0.81      1005\n",
            "\n",
            "    accuracy                           0.86      3000\n",
            "   macro avg       0.84      0.87      0.85      3000\n",
            "weighted avg       0.87      0.86      0.86      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame for predictions\n",
        "output = pd.DataFrame({\n",
        "    'UID': test_data['UID'],  # Use the correct column name from your test data\n",
        "    'Prediction': test_predictions\n",
        "})\n",
        "# Save predictions to a CSV file\n",
        "output.to_csv('predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "xmiRGBDv9BYE"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XiqcJpE79EC8"
      },
      "execution_count": 51,
      "outputs": []
    }
  ]
}